{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9fec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention.query_dense.weight: tensor([[ 0.0086, -0.0023,  0.0165,  ..., -0.0220, -0.0058,  0.0093],\n",
      "        [ 0.0014, -0.0207, -0.0080,  ...,  0.0231, -0.0049, -0.0135],\n",
      "        [ 0.0247, -0.0222,  0.0211,  ..., -0.0042,  0.0166, -0.0159],\n",
      "        ...,\n",
      "        [ 0.0013, -0.0227, -0.0110,  ..., -0.0179, -0.0017,  0.0226],\n",
      "        [-0.0105, -0.0239, -0.0234,  ...,  0.0281,  0.0168,  0.0117],\n",
      "        [ 0.0011, -0.0227,  0.0273,  ...,  0.0108, -0.0186,  0.0168]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 파일 경로 설정\n",
    "pt_file_path = \"../../model/bgem3_cluster/save/clustering_layer.pt\" # 파인튜닝 이전 랜덤 초기화 값\n",
    "\n",
    "# 가중치 로드 (map_location='cpu'는 GPU 없이도 가능하게 함)\n",
    "state_dict = torch.load(pt_file_path, map_location=\"cpu\")\n",
    "\n",
    "# 전체 키와 텐서 사이즈 확인\n",
    "for key, value in state_dict.items():\n",
    "    # print(f\"{key}: {value.shape}\")\n",
    "    # print(f\"{key}: {value}\")/\n",
    "    if key == 'attention.query_dense.weight':\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention.query_dense.weight: tensor([[-0.0062,  0.0284,  0.0092,  ...,  0.0111, -0.0007, -0.0233],\n",
      "        [-0.0097,  0.0185,  0.0216,  ...,  0.0288, -0.0115,  0.0305],\n",
      "        [ 0.0264,  0.0090,  0.0058,  ..., -0.0129,  0.0268, -0.0051],\n",
      "        ...,\n",
      "        [ 0.0243, -0.0161, -0.0172,  ..., -0.0179, -0.0296, -0.0094],\n",
      "        [ 0.0088, -0.0133, -0.0139,  ...,  0.0268, -0.0310,  0.0053],\n",
      "        [ 0.0259,  0.0062,  0.0255,  ...,  0.0083,  0.0118, -0.0023]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 파일 경로 설정\n",
    "pt_file_path = \"../../model/bgem3/save/clustering_layer.pt\" # 파인튜닝 이전 랜덤 초기화 값\n",
    "\n",
    "# 가중치 로드 (map_location='cpu'는 GPU 없이도 가능하게 함)\n",
    "state_dict = torch.load(pt_file_path, map_location=\"cpu\")\n",
    "\n",
    "# 전체 키와 텐서 사이즈 확인\n",
    "for key, value in state_dict.items():\n",
    "    # print(f\"{key}: {value.shape}\")\n",
    "    # print(f\"{key}: {value}\")/\n",
    "    if key == 'attention.query_dense.weight':\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60682d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
