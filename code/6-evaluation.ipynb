{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e28f4b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ecef3785e2421d841ba9c3192c0187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '219',\n",
       " 'title': '제87조',\n",
       " 'query': '제87조(내란) 대한민국 영토의 전부 또는 일부에서 국가권력을 배제하거나 국헌을 문란하게 할 목적으로 폭동을 일으킨 자는 다음 각 호의 구분에 따라 처벌한다',\n",
       " 'pos': ['피의자는 내각 총사퇴와 대통령 퇴진을 명분으로 시민들을 조직, 주요 행정기관을 공격하고 일부 국회의원의 신변을 위협하는 방식으로 국헌을 문란하게 할 것을 기도하였다.'],\n",
       " 'neg': ['피고인은 회사 내부의 전자기록 문서를 삭제하여 이후 업무 처리가 불가능하도록 함으로써 피해자의 업무 집행을 방해하였다.',\n",
       "  '피고인은 자신이 소유한 광갱 내에서 폭발물 취급 미숙으로 소규모 폭발 사고를 일으켜 광산 내부 근로자 및 인근 주민에게 공공의 위험을 야기하였다.',\n",
       "  '피고인은 자기 소유의 상가건물이 타인에게 근저당권 설정된 사실을 알면서도, 근저당권자의 동의 없이 무단으로 임대차계약을 체결하였다.',\n",
       "  '피고인은 통근 기차가 통과하는 철로에 폭약을 장치하여 기차를 탈선, 전복시켰다.',\n",
       "  '피고인은 2023년 11월 18일 인터넷 스포츠 도박사이트에 접속해 K리그 경기에 돈을 배팅하여 총 60만원의 도박행위를 하였다.',\n",
       "  '피의자는 피해자가 부적절한 관계를 가지고 있다는 거짓 주장을 다수에게 전달하여 사회적 평판을 실추시켰다.',\n",
       "  '피고인은 인터넷 방송 소재를 마련할 목적으로 공동묘지에서 시신 일부를 훼손하고 장난스러운 내용으로 영상을 제작하여 불특정 다수에게 공개하였다.',\n",
       "  '피고인은 밤 10시경 피해자 E가 점유한 오피스텔 숙소 유리문을 파손한 뒤 방으로 들어가 휴대폰과 현금을 절취하였다.']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Features, Value\n",
    "\n",
    "fpath = \"../data/relevant_incidents_test_minedHN.jsonl\"\n",
    "ds = load_dataset('json', data_files=fpath)['train']\n",
    "\n",
    "# 새 피처 정의\n",
    "new_features = Features({\n",
    "    'id': Value('string'),\n",
    "    'title': ds.features['title'],\n",
    "    'query': ds.features['query'],\n",
    "    'pos': ds.features['pos'],\n",
    "    'neg': ds.features['neg'],\n",
    "})\n",
    "\n",
    "# ds = ds(new_features)\n",
    "\n",
    "\n",
    "def int_to_str(row):\n",
    "    row['id'] = str(row['id'])\n",
    "    return row\n",
    "\n",
    "ds = ds.map(features=new_features)\n",
    "# ds = ds.map(int_to_str, features=new_features)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530b8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ds.select_columns(['id', 'query'])\n",
    "queries = queries.rename_column('query', 'text')\n",
    "\n",
    "corpus = ds.select_columns(['id', 'pos'])\n",
    "corpus = corpus.rename_column('pos', 'text')\n",
    "\n",
    "qrels = ds.select_columns(['id'])\n",
    "qrels = qrels.rename_column('id', 'qid')\n",
    "qrels = qrels.add_column('docid', ds['id'])\n",
    "qrels = qrels.add_column('relevance', [1] * len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51da8336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '220', 'text': '우두머리는 사형 무기징역 또는 무기금고에 처한다'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9030e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '220', 'text': ['피고인은 내부에서 최고위직을 맡아 내란을 주도하며, 폭동 발생 시 주요 작전을 총괄하였다.']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877c9c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': '220', 'docid': '220', 'relevance': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c43e9ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efb8038af5b4265bef0c03fa0e88c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c588e28a7d4c82b2a1c6524809b433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0340588bab80438891e7e36e2128d466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15246"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.to_json(\"../data/test_queries.jsonl\", force_ascii=False)\n",
    "corpus.to_json(\"../data/test_corpus.jsonl\", force_ascii=False)\n",
    "qrels.to_json(\"../data/test_qrels.jsonl\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e21141",
   "metadata": {},
   "source": [
    "### KLAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deeb4dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071f179953784909a6be061cea270a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f98390681b44c9ae80e26d32e3ca88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KLAID.py:   0%|          | 0.00/3.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7694d739ebdb49859f802738c14cf546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/60.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8ba8b878864cdda397a4ab3784be36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/161192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# legal judgment prediction\n",
    "dataset = load_dataset(\"lawcompany/KLAID\", 'ljp') # Specify a cache directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b4dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b28754bd93c4d81a9c19331a37992de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/161192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['laws_service_id', 'fact', 'laws_service'],\n",
       "    num_rows: 89943\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def only_criminal(row):\n",
    "    laws = row['laws_service'].split(\",\")\n",
    "    if all(law.startswith(\"형법\") for law in laws) : return row\n",
    "\n",
    "ds_criminal = dataset['train'].filter(only_criminal)\n",
    "\n",
    "ds_criminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239c27be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'형법 제260조 제1항': 10224,\n",
       " '형법 제314조 제1항': 5927,\n",
       " '형법 제332조': 379,\n",
       " '형법 제329조': 6442,\n",
       " '형법 제257조 제1항': 19406,\n",
       " '형법 제245조': 1258,\n",
       " '형법 제362조 제1항': 240,\n",
       " '형법 제284조': 2438,\n",
       " '형법 제283조 제2항': 48,\n",
       " '형법 제283조 제1항': 3106,\n",
       " '형법 제261조': 1645,\n",
       " '형법 제366조': 5136,\n",
       " '형법 제319조 제1항': 1933,\n",
       " '형법 제347조 제1항': 12278,\n",
       " '형법 제355조 제1항': 4221,\n",
       " '형법 제323조': 964,\n",
       " '형법 제136조 제1항': 11615,\n",
       " '형법 제299조': 568,\n",
       " '형법 제298조': 2971,\n",
       " '형법 제311조': 3771,\n",
       " '형법 제258조의2 제1항': 5945,\n",
       " '형법 제257조 제2항': 143,\n",
       " '형법 제246조 제1항': 430,\n",
       " '형법 제144조 제1항': 215,\n",
       " '형법 제262조': 549,\n",
       " '형법 제259조 제1항': 96,\n",
       " '형법 제297조': 297,\n",
       " '형법 제319조 제2항': 184,\n",
       " '형법 제152조 제1항': 435,\n",
       " '형법 제330조': 1326,\n",
       " '형법 제356조': 1846,\n",
       " '형법 제185조': 531,\n",
       " '형법 제307조 제2항': 686,\n",
       " '형법 제268조': 504,\n",
       " '형법 제355조 제2항': 548,\n",
       " '형법 제264조': 112,\n",
       " '형법 제331조 제2항': 479,\n",
       " '형법 제331조 제1항': 658,\n",
       " '형법 제347조 제2항': 105,\n",
       " '형법 제156조': 929,\n",
       " '형법 제258조 제2항': 27,\n",
       " '형법 제258조 제1항': 53,\n",
       " '형법 제350조 제1항': 182,\n",
       " '형법 제360조 제1항': 363,\n",
       " '형법 제307조 제1항': 230,\n",
       " '형법 제267조': 26,\n",
       " '형법 제347조의2': 193,\n",
       " '형법 제369조 제1항': 376,\n",
       " '형법 제357조 제2항': 25,\n",
       " '형법 제357조 제1항': 81,\n",
       " '형법 제170조 제1항': 56,\n",
       " '형법 제164조 제1항': 167,\n",
       " '형법 제337조': 45,\n",
       " '형법 제266조 제1항': 281,\n",
       " '형법 제246조 제2항': 101,\n",
       " '형법 제141조 제1항': 207,\n",
       " '형법 제334조 제2항': 70,\n",
       " '형법 제334조 제1항': 72,\n",
       " '형법 제333조': 147,\n",
       " '형법 제335조': 27,\n",
       " '형법 제297조의2': 105,\n",
       " '형법 제301조': 128,\n",
       " '형법 제151조 제1항': 112,\n",
       " '형법 제348조 제1항': 40,\n",
       " '형법 제260조 제2항': 49,\n",
       " '형법 제285조': 14,\n",
       " '형법 제331조의2': 32,\n",
       " '형법 제305조 제1항': 23}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws_count = {}\n",
    "\n",
    "for data in ds_criminal:\n",
    "  for law in data['laws_service'].split(','):\n",
    "    if law in laws_count:\n",
    "      laws_count[law] += 1\n",
    "    else:\n",
    "      laws_count[law] = 1\n",
    "\n",
    "laws_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a28fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d71a34d15624402be6c82af5201cf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f3bcda4f0e4968a9ac414fb3d659bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "laws_fpath = \"../data/queries-edited-filtered.jsonl\"\n",
    "laws_edgecase_fpath = \"../data/queries-edited.jsonl\"\n",
    "\n",
    "laws = load_dataset('json', data_files=laws_fpath)['train']\n",
    "laws_edgecase = load_dataset('json', data_files=laws_edgecase_fpath)['train'].to_pandas()\n",
    "\n",
    "laws_name = []\n",
    "for law in laws:\n",
    "  laws_name.append(law['title'])\n",
    "\n",
    "laws_set = set(laws_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d353a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<누락>>\n",
      "\n",
      "형법 제332조\n",
      "688    제332조(상습범) 상습으로 제329조 내지 제331조의2의 죄를 범한 자는 그 죄...\n",
      "Name: content, dtype: object\n",
      "형법 제264조\n",
      "545    제264조(상습범) 상습으로 제257조 제258조 제258조의2 제260조 또는 제...\n",
      "Name: content, dtype: object\n",
      "형법 제285조\n",
      "591    제285조(상습범) 상습으로 제283조제1항 제2항 또는 전조의 죄를 범한 때에는 ...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"<<누락>>\\n\")\n",
    "\n",
    "for law in laws_count.keys():\n",
    "  if law not in laws_set:\n",
    "    print(law)\n",
    "    print(laws_edgecase.loc[laws_edgecase['title'] == law]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d9ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'laws_service_id': 34,\n",
       " 'fact': '피고인 A은 노동일에 종사 중이다. 피고인은 2017. 2. 2. 20:00경 부산 해운대구 B, C식당 앞 노상에서 술을 마시고 D의 포터차량을 타려다가 주변에 있던 E 일행이 음주운전을 하려 한다고 말을 건 일로 서로 시비가 되었다. 피고인은 피해자 E과 시비를 벌이다. 피해자를 밀치고, 인근 주차장에서 들고 온 약 1.5m 길이의 쇠막대기로 E의 머리와 어깨 부위를 4~5회 가량 내리쳐 피해자를 폭행하였다.',\n",
       " 'laws_service': '형법 제260조 제1항'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_criminal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d0619b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0, 'title': '형법 제1조', 'content': '제1조(범죄의 성립과 처벌)'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97f28312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Value\n",
    "import json\n",
    "\n",
    "\n",
    "def mapper(\n",
    "    keyword,\n",
    "    laws: Dataset,\n",
    "):\n",
    "    df_laws = laws.to_pandas()\n",
    "    # 검색\n",
    "    matched = df_laws.loc[df_laws[\"title\"] == keyword]\n",
    "\n",
    "    if not matched.empty:\n",
    "        id = str(matched.index[0])\n",
    "        text = matched[\"content\"].iloc[0]\n",
    "        return id, text\n",
    "    else:\n",
    "        raise ValueError(f\"No results were found for the keyword {keyword}\")\n",
    "\n",
    "\n",
    "def trans_to_testset(dataset: Dataset, laws: Dataset, fname_prefix: str = \"\"):\n",
    "    queries = laws.cast_column('id', Value('string'))\n",
    "    queries = queries.rename_column('content', 'text')\n",
    "    queries = queries.remove_columns(['title'])\n",
    "\n",
    "    qids = []\n",
    "    corpus = []\n",
    "    qrels = []\n",
    "    for i, data in enumerate(dataset):\n",
    "        docid = str(i)\n",
    "        corpus.append({\"id\": docid, \"text\": [data[\"fact\"]]})\n",
    "        for keyword in list(map(lambda x: x.strip(), data[\"laws_service\"].split(\",\"))):\n",
    "            qid, _ = mapper(keyword, laws)\n",
    "            qids.append(qid)\n",
    "            qrels.append({\"qid\": qid, \"docid\": docid, \"relevance\": 1})\n",
    "\n",
    "    queries = queries.filter(lambda x : x if x['id'] in qids else None)\n",
    "\n",
    "    # save\n",
    "    fname_prefix = f\"{fname_prefix}_\" if fname_prefix != \"\" else \"\"\n",
    "    queries.to_json(fname_prefix + \"test_queries.jsonl\", force_ascii=False)\n",
    "\n",
    "    with open(fname_prefix + \"test_corpus.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for c in corpus:\n",
    "            json.dump(c, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(fname_prefix + \"test_qrels.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for q in qrels:\n",
    "            json.dump(q, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33f66a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# legal judgment prediction\n",
    "dataset = load_dataset(\"lawcompany/KLAID\", 'ljp') # Specify a cache directory\n",
    "\n",
    "def only_criminal(row):\n",
    "    laws = row['laws_service'].split(\",\")\n",
    "    if all(law.startswith(\"형법\") for law in laws) : return row\n",
    "\n",
    "ds_criminal = dataset['train'].filter(only_criminal)\n",
    "\n",
    "laws = load_dataset('json', data_files=\"../data/queries-edited.jsonl\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "619325e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26121cdf8a844045b0872ea0a80f4c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/762 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e51ccfd6a2c4bcc80f8d94a3a5301a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trans_to_testset(ds_criminal.select([i for i in range(0, 3000)]), laws, \"KLAID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d12b1488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37440dc9f3b4bdca52bfad87280c966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298cfc81922949258249cc77ec31de2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f730ec630745919429252f60b52ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_dir = \"../data\"\n",
    "\n",
    "queries = load_dataset(\"json\", data_files=f\"{dataset_dir}/KLAID_test_queries.jsonl\")[\"train\"]\n",
    "corpus = load_dataset(\"json\", data_files=f\"{dataset_dir}/KLAID_test_corpus.jsonl\")[\"train\"]\n",
    "qrels = load_dataset(\"json\", data_files=f\"{dataset_dir}/KLAID_test_qrels.jsonl\")[\"train\"]\n",
    "\n",
    "queries_text = queries[\"text\"]\n",
    "corpus_text = [text for sub in corpus[\"text\"] for text in sub]\n",
    "\n",
    "qrels_dict = {}\n",
    "for line in qrels:\n",
    "    if line[\"qid\"] not in qrels_dict:\n",
    "        qrels_dict[line[\"qid\"]] = {}\n",
    "    qrels_dict[line[\"qid\"]][line[\"docid\"]] = line[\"relevance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5f23b",
   "metadata": {},
   "source": [
    "### evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "## data loading ##\n",
    "\n",
    "dataset_dir = \"/data2/local_datasets/bge-m3/data\"\n",
    "# queries = load_dataset(\"json\", data_files=f\"{dataset_dir}/test_queries.jsonl\")[\"train\"]\n",
    "# corpus = load_dataset(\"json\", data_files=f\"{dataset_dir}/test_corpus.jsonl\")[\"train\"]\n",
    "# qrels = load_dataset(\"json\", data_files=f\"{dataset_dir}/test_qrels.jsonl\")[\"train\"]\n",
    "\n",
    "queries = load_dataset(\"json\", data_files=f\"{dataset_dir}/KLAID_test_queries.jsonl\")[\"train\"]\n",
    "corpus = load_dataset(\"json\", data_files=f\"{dataset_dir}/KLAID_test_corpus.jsonl\")[\"train\"]\n",
    "qrels = load_dataset(\"json\", data_files=f\"{dataset_dir}/KLAID_test_qrels.jsonl\")[\"train\"]\n",
    "\n",
    "queries_text = queries[\"text\"]\n",
    "corpus_text = [text for sub in corpus[\"text\"] for text in sub]\n",
    "\n",
    "qrels_dict = {}\n",
    "for line in qrels:\n",
    "    if line[\"qid\"] not in qrels_dict:\n",
    "        qrels_dict[line[\"qid\"]] = {}\n",
    "    qrels_dict[line[\"qid\"]][line[\"docid\"]] = line[\"relevance\"]\n",
    "\n",
    "\n",
    "## Similarity search method ##\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def search(model, queries_text, corpus_text):\n",
    "\n",
    "    queries_embeddings = model.encode_queries(queries_text)\n",
    "    corpus_embeddings = model.encode_corpus(corpus_text)\n",
    "\n",
    "    # create and store the embeddings in a Faiss index\n",
    "    dim = corpus_embeddings.shape[-1]\n",
    "    index = faiss.index_factory(dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "    corpus_embeddings = corpus_embeddings.astype(np.float32)\n",
    "    index.train(corpus_embeddings)\n",
    "    index.add(corpus_embeddings)\n",
    "\n",
    "    query_size = len(queries_embeddings)\n",
    "\n",
    "    all_scores = []\n",
    "    all_indices = []\n",
    "\n",
    "    # search top 100 answers for all the queries\n",
    "    for i in tqdm(range(0, query_size, 32), desc=\"Searching\"):\n",
    "        j = min(i + 32, query_size)\n",
    "        query_embedding = queries_embeddings[i:j]\n",
    "        score, indice = index.search(query_embedding.astype(np.float32), k=100)\n",
    "        all_scores.append(score)\n",
    "        all_indices.append(indice)\n",
    "\n",
    "    all_scores = np.concatenate(all_scores, axis=0)\n",
    "    all_indices = np.concatenate(all_indices, axis=0)\n",
    "\n",
    "    # store the results into the format for evaluation\n",
    "    results = {}\n",
    "    for idx, (scores, indices) in enumerate(zip(all_scores, all_indices)):\n",
    "        results[queries[\"id\"][idx]] = {}\n",
    "        for score, index in zip(scores, indices):\n",
    "            if index != -1:\n",
    "                results[queries[\"id\"][idx]][corpus[\"id\"][index]] = float(score)\n",
    "\n",
    "    return results\n",
    "\n",
    "## debugging\n",
    "def evaluate_mrr(\n",
    "    qrels: Dict[str, Dict[str, int]],\n",
    "    results: Dict[str, Dict[str, float]],\n",
    "    k_values: List[int],\n",
    ") -> Tuple[Dict[str, float]]:\n",
    "    mrr = defaultdict(list)\n",
    "\n",
    "    k_max, top_hits = max(k_values), {}\n",
    "\n",
    "    # debugging\n",
    "    qids = []\n",
    "    for query_id, doc_scores in results.items():\n",
    "        # debugging\n",
    "        qids.append(query_id)\n",
    "        top_hits[query_id] = sorted(\n",
    "            doc_scores.items(), key=lambda item: item[1], reverse=True\n",
    "        )[0:k_max]\n",
    "\n",
    "    print(qids)\n",
    "\n",
    "    for query_id in top_hits:\n",
    "        query_relevant_docs = {\n",
    "            doc_id for doc_id in qrels[query_id] if qrels[query_id][doc_id] > 0\n",
    "        }\n",
    "        for k in k_values:\n",
    "            rr = 0\n",
    "            for rank, hit in enumerate(top_hits[query_id][0:k], 1):\n",
    "                if hit[0] in query_relevant_docs:\n",
    "                    rr = 1.0 / rank\n",
    "                    break\n",
    "            mrr[f\"MRR@{k}\"].append(rr)\n",
    "\n",
    "    for k in k_values:\n",
    "        mrr[f\"MRR@{k}\"] = round(sum(mrr[f\"MRR@{k}\"]) / len(qrels), 5)\n",
    "\n",
    "    return mrr\n",
    "\n",
    "\n",
    "## Evaluation ##\n",
    "\n",
    "from FlagEmbedding.abc.evaluation.utils import evaluate_metrics, evaluate_mrr\n",
    "from FlagEmbedding import FlagModel\n",
    "\n",
    "k_values = [10, 100]\n",
    "\n",
    "raw_name = \"BAAI/bge-m3\"\n",
    "finetuned_path = \"/data2/local_datasets/bge-m3/ft_model\"\n",
    "\n",
    "## Raw model\n",
    "\n",
    "raw_model = FlagModel(\n",
    "    raw_name,\n",
    "    # query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "    devices=[0],\n",
    "    use_fp16=False,\n",
    ")\n",
    "\n",
    "results = search(raw_model, queries_text, corpus_text)\n",
    "\n",
    "eval_res = evaluate_metrics(qrels_dict, results, k_values)\n",
    "mrr = evaluate_mrr(qrels_dict, results, k_values)\n",
    "\n",
    "print(\"## Raw model ##\")\n",
    "\n",
    "for res in eval_res:\n",
    "    print(res)\n",
    "print(mrr)\n",
    "\n",
    "## Fine tuning model\n",
    "\n",
    "ft_model = FlagModel(\n",
    "    finetuned_path,\n",
    "    # query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "    devices=[0],\n",
    "    use_fp16=False,\n",
    ")\n",
    "\n",
    "results = search(ft_model, queries_text, corpus_text)\n",
    "\n",
    "eval_res = evaluate_metrics(qrels_dict, results, k_values)\n",
    "mrr = evaluate_mrr(qrels_dict, results, k_values)\n",
    "\n",
    "print(\"## Fine-tuning model ##\")\n",
    "\n",
    "for res in eval_res:\n",
    "    print(res)\n",
    "print(mrr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ccfd4f",
   "metadata": {},
   "source": [
    "### evaluation.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682cc5c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/bash\n",
    "#SBATCH -J bge-m3\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --cpus-per-gpu=8\n",
    "#SBATCH --mem-per-gpu=32G\n",
    "#SBATCH -w aurora-g6\n",
    "#SBATCH -p batch_ugrad\n",
    "#SBATCH -t 1-0\n",
    "#SBATCH -o logs/slurm-%A.out\n",
    "\n",
    "python evaluation.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
